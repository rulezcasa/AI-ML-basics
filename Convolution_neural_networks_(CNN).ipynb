{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHKrA3tFOYyk"
   },
   "source": [
    "### Importing model building libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nauOL0wCONUv"
   },
   "outputs": [],
   "source": [
    "#ANN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#CNN\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGiH3rQaO6Rv"
   },
   "source": [
    "### Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "F84wh9TjOcn7"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vTeY0fIrO8FU"
   },
   "outputs": [],
   "source": [
    "#configure image data generator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XurbboO1P-OF",
    "outputId": "926369de-3c86-4170-8767-8881ca190dd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1238 images belonging to 4 classes.\n",
      "Found 326 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#Applying image data generator functionality to train and test images\n",
    "x_train=train_datagen.flow_from_directory(r\"/Users/casarulez/AI:ML externship/AI-ML-externship/dataset/Training\",target_size=(64,64),batch_size=32,class_mode=\"categorical\")\n",
    "x_test=test_datagen.flow_from_directory(r\"/Users/casarulez/AI:ML externship/AI-ML-externship/dataset/Testing\",target_size=(64,64),batch_size=32,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4-8CyEjQ5L-",
    "outputId": "829b089f-aac8-4022-fa0f-27f4b1612c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bears': 0, 'crows': 1, 'elephants': 2, 'rats': 3}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJoNZZUARUYG"
   },
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lgeW34VSRNkF"
   },
   "outputs": [],
   "source": [
    "#Intializing the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nkK8ksBnvBN-"
   },
   "outputs": [],
   "source": [
    "#Adding convolution layer (No. of filters, size of filter, input shape, activation=relu)\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0keseRV7v7I2"
   },
   "outputs": [],
   "source": [
    "#Adding max pooling layer(pool_size)\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bVEIW5yPwgR9"
   },
   "outputs": [],
   "source": [
    "#Adding flatten layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3srxVTAIwuTZ"
   },
   "source": [
    "The flatten layer provides output as input for ANN¯¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qe1ej899w0Nb"
   },
   "outputs": [],
   "source": [
    "#ANN hidden layer\n",
    "model.add(Dense(units=128,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cxsw1I91wm7U"
   },
   "outputs": [],
   "source": [
    "#Adding output layer\n",
    "model.add(Dense(units=4,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9mbUHoxhwzU5"
   },
   "outputs": [],
   "source": [
    "#Compiling the model(loss function,optimizer, accuracy)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-iLQMaCxtps",
    "outputId": "1c8ba7d9-9873-4807-bdd4-7d9805297f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 17:14:04.760970: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 4s 93ms/step - loss: 1.5967 - accuracy: 0.3118 - val_loss: 1.2545 - val_accuracy: 0.4219\n",
      "Epoch 2/5\n",
      "39/39 [==============================] - 4s 94ms/step - loss: 1.0878 - accuracy: 0.5541 - val_loss: 0.9046 - val_accuracy: 0.6469\n",
      "Epoch 3/5\n",
      "39/39 [==============================] - 4s 95ms/step - loss: 0.8613 - accuracy: 0.6559 - val_loss: 0.7073 - val_accuracy: 0.7406\n",
      "Epoch 4/5\n",
      "39/39 [==============================] - 4s 95ms/step - loss: 0.7479 - accuracy: 0.7149 - val_loss: 0.6287 - val_accuracy: 0.7688\n",
      "Epoch 5/5\n",
      "39/39 [==============================] - 4s 94ms/step - loss: 0.6582 - accuracy: 0.7569 - val_loss: 0.4679 - val_accuracy: 0.8281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x283a68610>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting model\n",
    "model.fit(x_train,steps_per_epoch=39,epochs=5,validation_data=x_test,validation_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8C3dxyfOyRjA"
   },
   "source": [
    "Steps per epoch = No. of samples in your training/batch size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVRV5HRpx_jl",
    "outputId": "93e2e790-4ab5-42d5-b41c-ea124ddb732b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30752)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3936384   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,937,796\n",
      "Trainable params: 3,937,796\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guWQSiYz1Xik"
   },
   "source": [
    "For Convolution layer:\n",
    "\n",
    "1. No. of filters *(input_channels*window_size+1)=Number of paramaters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BC6DsMxz1l3i"
   },
   "source": [
    "For Dense layers:\n",
    "\n",
    "1. Output_size*(input_size+1)==number_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8lxUI1F3mSN"
   },
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48G2Tr2L0dDT",
    "outputId": "5cb1bb21-c8f9-48e9-ed96-5d4ac289e563"
   },
   "outputs": [],
   "source": [
    "model.save(\"animal.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9Ztmzev39eL"
   },
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pzf_ss661aJ3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "EZwlXcl83_s3"
   },
   "outputs": [],
   "source": [
    "#Loading model\n",
    "import tensorflow as tf\n",
    "model=tf.keras.models.load_model(r\"/Users/casarulez/AI:ML externship/AI-ML-externship/animal.h5\",compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "ibcf7zJ45VQI",
    "outputId": "dce0ab5e-7d8b-4d5d-bc08-262cc1301215"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/elephant.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Loading an image\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m img\u001b[38;5;241m=\u001b[39m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/content/elephant.jpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m img\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[1;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/elephant.jpeg'"
     ]
    }
   ],
   "source": [
    "#Loading an image\n",
    "img=image.load_img(r\"/content/elephant.jpeg\",target_size=(64,64))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q83XiQX37HNm",
    "outputId": "ef4c40f3-2ffb-48f0-b242-5022f72a9856"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[219., 222., 227.],\n",
       "        [219., 222., 227.],\n",
       "        [219., 222., 227.],\n",
       "        ...,\n",
       "        [214., 217., 224.],\n",
       "        [214., 217., 224.],\n",
       "        [214., 217., 224.]],\n",
       "\n",
       "       [[221., 224., 229.],\n",
       "        [221., 224., 229.],\n",
       "        [221., 224., 229.],\n",
       "        ...,\n",
       "        [216., 219., 226.],\n",
       "        [216., 219., 226.],\n",
       "        [216., 219., 226.]],\n",
       "\n",
       "       [[222., 225., 230.],\n",
       "        [222., 225., 230.],\n",
       "        [222., 225., 230.],\n",
       "        ...,\n",
       "        [219., 222., 229.],\n",
       "        [219., 222., 229.],\n",
       "        [219., 222., 229.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[174., 155., 141.],\n",
       "        [172., 152., 141.],\n",
       "        [172., 152., 145.],\n",
       "        ...,\n",
       "        [134., 125., 120.],\n",
       "        [131., 122., 117.],\n",
       "        [136., 127., 122.]],\n",
       "\n",
       "       [[176., 157., 143.],\n",
       "        [174., 154., 143.],\n",
       "        [168., 148., 141.],\n",
       "        ...,\n",
       "        [131., 122., 117.],\n",
       "        [128., 119., 114.],\n",
       "        [137., 128., 123.]],\n",
       "\n",
       "       [[174., 155., 141.],\n",
       "        [171., 151., 140.],\n",
       "        [170., 150., 143.],\n",
       "        ...,\n",
       "        [125., 116., 111.],\n",
       "        [120., 111., 106.],\n",
       "        [127., 118., 113.]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3D array of pixels\n",
    "x=image.img_to_array(img)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZaumuvk8d7K"
   },
   "source": [
    "Since convolution layer is 4D, input data should be converted to 4D array while passimg for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gq3xNRDB73Zw",
    "outputId": "a26a6a60-e76c-42b0-b27a-0050b6681349"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.expand_dims(x,axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8sqMWhKd78hn",
    "outputId": "428ebdf7-8faf-4e5f-eb3c-20ddd6ad6f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 151ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsdfOxBV8-xu",
    "outputId": "f6bf580b-f9f1-430d-8c56-2385351aac77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class=np.argmax(pred,axis=1)\n",
    "pred_class[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wg8G7Io-OPg"
   },
   "outputs": [],
   "source": [
    "index=[\"bear\",\"crow\",\"elephant\",\"rat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FWRj5GMV_EBS",
    "outputId": "7b6ac727-383a-4997-c188-b0674e15e638"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'elephant'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=str(index[pred_class[0]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
